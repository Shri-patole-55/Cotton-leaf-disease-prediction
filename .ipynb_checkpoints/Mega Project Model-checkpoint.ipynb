{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7a60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e0111a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b28d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path=r\"dataset\\train\"\n",
    "validation_data_path=r\"dataset\\val\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "da36a279",
   "metadata": {},
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee44d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "# It generate more images using below parameters\n",
    "training_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                      rotation_range=40,\n",
    "                                      width_shift_range=0.2,\n",
    "                                      height_shift_range=0.2,\n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70629c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1579 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is a generator that will read pictures found in\n",
    "# at train_data_path, and indefinitely generate\n",
    "# batches of augmented image data\n",
    "training_data = training_datagen.flow_from_directory(train_data_path, # this is the target directory\n",
    "                                      target_size=(150, 150), # all images will be resized to 150x150\n",
    "                                      batch_size=32,\n",
    "                                      class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e8211d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bacterial Blight': 0,\n",
       " 'Curl Virus': 1,\n",
       " 'Fresh Cotton Leaf': 2,\n",
       " 'Sucking and Chewing Pest': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230fe6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 204 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for validation:\n",
    "# only rescaling\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# this is a similar generator, for validation data\n",
    "valid_data = valid_datagen.flow_from_directory(validation_data_path,\n",
    "                                  target_size=(150,150),\n",
    "                                  batch_size=32,\n",
    "                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b0827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [training_data[0][0][0] for i in range(5)]\n",
    "plt.show(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aa5b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path =r\"E:\\Cotton Leaf Disease Detection\\model\"\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "342618d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building cnn model\n",
    "cnn_model = keras.models.Sequential([\n",
    "                                    keras.layers.Conv2D(filters=32, kernel_size=3, input_shape=[150, 150, 3]),\n",
    "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                                    keras.layers.Conv2D(filters=64, kernel_size=3),\n",
    "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                                    keras.layers.Conv2D(filters=128, kernel_size=3),\n",
    "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),                                    \n",
    "                                    keras.layers.Conv2D(filters=256, kernel_size=3),\n",
    "                                    keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    " \n",
    "                                    keras.layers.Dropout(0.5),                                                                        \n",
    "                                    keras.layers.Flatten(), # neural network beulding\n",
    "                                    keras.layers.Dense(units=128, activation='relu'), # input layers\n",
    "                                    keras.layers.Dropout(0.1),                                    \n",
    "                                    keras.layers.Dense(units=256, activation='relu'),                                    \n",
    "                                    keras.layers.Dropout(0.25),                                    \n",
    "                                    keras.layers.Dense(units=4, activation='softmax') # output layer\n",
    "])\n",
    " \n",
    " \n",
    "\n",
    "cnn_model.compile(optimizer = Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ddd2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,028,228\n",
      "Trainable params: 2,028,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02239aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.2750 - accuracy: 0.4193\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59259, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 89s 2s/step - loss: 1.2750 - accuracy: 0.4193 - val_loss: 0.8646 - val_accuracy: 0.5926\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 1.0868 - accuracy: 0.5136\n",
      "Epoch 00002: val_accuracy improved from 0.59259 to 0.67407, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 74s 1s/step - loss: 1.0868 - accuracy: 0.5136 - val_loss: 0.8167 - val_accuracy: 0.6741\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.9484 - accuracy: 0.5744\n",
      "Epoch 00003: val_accuracy did not improve from 0.67407\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.9484 - accuracy: 0.5744 - val_loss: 0.7557 - val_accuracy: 0.6444\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.8597 - accuracy: 0.6257\n",
      "Epoch 00004: val_accuracy improved from 0.67407 to 0.71852, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.8597 - accuracy: 0.6257 - val_loss: 0.5871 - val_accuracy: 0.7185\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.8130 - accuracy: 0.6415\n",
      "Epoch 00005: val_accuracy did not improve from 0.71852\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.8130 - accuracy: 0.6415 - val_loss: 0.6926 - val_accuracy: 0.6889\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.7396 - accuracy: 0.6783\n",
      "Epoch 00006: val_accuracy did not improve from 0.71852\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.7396 - accuracy: 0.6783 - val_loss: 0.6537 - val_accuracy: 0.7185\n",
      "Epoch 7/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.7169 - accuracy: 0.6903\n",
      "Epoch 00007: val_accuracy improved from 0.71852 to 0.79259, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.7169 - accuracy: 0.6903 - val_loss: 0.5908 - val_accuracy: 0.7926\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6737 - accuracy: 0.7118\n",
      "Epoch 00008: val_accuracy did not improve from 0.79259\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.6737 - accuracy: 0.7118 - val_loss: 0.5428 - val_accuracy: 0.7704\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.7182\n",
      "Epoch 00009: val_accuracy improved from 0.79259 to 0.81481, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.6923 - accuracy: 0.7182 - val_loss: 0.4963 - val_accuracy: 0.8148\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6369 - accuracy: 0.7384\n",
      "Epoch 00010: val_accuracy improved from 0.81481 to 0.88148, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.6369 - accuracy: 0.7384 - val_loss: 0.3489 - val_accuracy: 0.8815\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6157 - accuracy: 0.7505\n",
      "Epoch 00011: val_accuracy did not improve from 0.88148\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.6157 - accuracy: 0.7505 - val_loss: 0.4222 - val_accuracy: 0.8593\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.7606\n",
      "Epoch 00012: val_accuracy did not improve from 0.88148\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.6150 - accuracy: 0.7606 - val_loss: 0.5566 - val_accuracy: 0.8296\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5741 - accuracy: 0.7568\n",
      "Epoch 00013: val_accuracy did not improve from 0.88148\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.5741 - accuracy: 0.7568 - val_loss: 0.4479 - val_accuracy: 0.8444\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.7638\n",
      "Epoch 00014: val_accuracy did not improve from 0.88148\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.5964 - accuracy: 0.7638 - val_loss: 0.5371 - val_accuracy: 0.8148\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5761 - accuracy: 0.7600\n",
      "Epoch 00015: val_accuracy did not improve from 0.88148\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.5761 - accuracy: 0.7600 - val_loss: 0.3399 - val_accuracy: 0.8667\n",
      "Epoch 16/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5411 - accuracy: 0.7815\n",
      "Epoch 00016: val_accuracy did not improve from 0.88148\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.5411 - accuracy: 0.7815 - val_loss: 0.3469 - val_accuracy: 0.8741\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5512 - accuracy: 0.7809\n",
      "Epoch 00017: val_accuracy did not improve from 0.88148\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.5512 - accuracy: 0.7809 - val_loss: 0.5361 - val_accuracy: 0.7778\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5357 - accuracy: 0.7771\n",
      "Epoch 00018: val_accuracy did not improve from 0.88148\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.5357 - accuracy: 0.7771 - val_loss: 0.3976 - val_accuracy: 0.8815\n",
      "Epoch 19/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.5016 - accuracy: 0.7935\n",
      "Epoch 00019: val_accuracy did not improve from 0.88148\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.5016 - accuracy: 0.7935 - val_loss: 0.3975 - val_accuracy: 0.8296\n",
      "Epoch 20/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.8005\n",
      "Epoch 00020: val_accuracy improved from 0.88148 to 0.91111, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.4955 - accuracy: 0.8005 - val_loss: 0.3455 - val_accuracy: 0.9111\n",
      "Epoch 21/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4710 - accuracy: 0.8106\n",
      "Epoch 00021: val_accuracy did not improve from 0.91111\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.4710 - accuracy: 0.8106 - val_loss: 0.3702 - val_accuracy: 0.8667\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4484 - accuracy: 0.8087\n",
      "Epoch 00022: val_accuracy did not improve from 0.91111\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.4484 - accuracy: 0.8087 - val_loss: 0.3189 - val_accuracy: 0.8889\n",
      "Epoch 23/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.8284\n",
      "Epoch 00023: val_accuracy improved from 0.91111 to 0.91852, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.4503 - accuracy: 0.8284 - val_loss: 0.2651 - val_accuracy: 0.9185\n",
      "Epoch 24/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4726 - accuracy: 0.8087\n",
      "Epoch 00024: val_accuracy did not improve from 0.91852\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.4726 - accuracy: 0.8087 - val_loss: 0.2835 - val_accuracy: 0.9185\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.8239\n",
      "Epoch 00025: val_accuracy did not improve from 0.91852\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.4261 - accuracy: 0.8239 - val_loss: 0.3008 - val_accuracy: 0.8815\n",
      "Epoch 26/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3983 - accuracy: 0.8448\n",
      "Epoch 00026: val_accuracy did not improve from 0.91852\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.3983 - accuracy: 0.8448 - val_loss: 0.2142 - val_accuracy: 0.9037\n",
      "Epoch 27/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.8499\n",
      "Epoch 00027: val_accuracy did not improve from 0.91852\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.3926 - accuracy: 0.8499 - val_loss: 0.2749 - val_accuracy: 0.8963\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.8436\n",
      "Epoch 00028: val_accuracy did not improve from 0.91852\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.4056 - accuracy: 0.8436 - val_loss: 0.2265 - val_accuracy: 0.9111\n",
      "Epoch 29/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.8607\n",
      "Epoch 00029: val_accuracy did not improve from 0.91852\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.3836 - accuracy: 0.8607 - val_loss: 0.2382 - val_accuracy: 0.8963\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.8524\n",
      "Epoch 00030: val_accuracy improved from 0.91852 to 0.96296, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.3707 - accuracy: 0.8524 - val_loss: 0.2217 - val_accuracy: 0.9630\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3306 - accuracy: 0.8664\n",
      "Epoch 00031: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.3306 - accuracy: 0.8664 - val_loss: 0.2329 - val_accuracy: 0.9259\n",
      "Epoch 32/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.8854\n",
      "Epoch 00032: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.3117 - accuracy: 0.8854 - val_loss: 0.1913 - val_accuracy: 0.9407\n",
      "Epoch 33/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.8670\n",
      "Epoch 00033: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.3574 - accuracy: 0.8670 - val_loss: 0.2467 - val_accuracy: 0.8815\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3912 - accuracy: 0.8493\n",
      "Epoch 00034: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.3912 - accuracy: 0.8493 - val_loss: 0.2822 - val_accuracy: 0.9037\n",
      "Epoch 35/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.8835\n",
      "Epoch 00035: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.3166 - accuracy: 0.8835 - val_loss: 0.1999 - val_accuracy: 0.9259\n",
      "Epoch 36/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.8860\n",
      "Epoch 00036: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.3093 - accuracy: 0.8860 - val_loss: 0.2142 - val_accuracy: 0.9185\n",
      "Epoch 37/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.8879\n",
      "Epoch 00037: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.3007 - accuracy: 0.8879 - val_loss: 0.2594 - val_accuracy: 0.9111\n",
      "Epoch 38/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.8765\n",
      "Epoch 00038: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.3262 - accuracy: 0.8765 - val_loss: 0.2070 - val_accuracy: 0.8889\n",
      "Epoch 39/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2863 - accuracy: 0.8968\n",
      "Epoch 00039: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2863 - accuracy: 0.8968 - val_loss: 0.1332 - val_accuracy: 0.9481\n",
      "Epoch 40/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.9006\n",
      "Epoch 00040: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2720 - accuracy: 0.9006 - val_loss: 0.2544 - val_accuracy: 0.8889\n",
      "Epoch 41/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.8917\n",
      "Epoch 00041: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2811 - accuracy: 0.8917 - val_loss: 0.1269 - val_accuracy: 0.9556\n",
      "Epoch 42/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.8930\n",
      "Epoch 00042: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2878 - accuracy: 0.8930 - val_loss: 0.1263 - val_accuracy: 0.9407\n",
      "Epoch 43/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2411 - accuracy: 0.9132\n",
      "Epoch 00043: val_accuracy did not improve from 0.96296\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2411 - accuracy: 0.9132 - val_loss: 0.1492 - val_accuracy: 0.9630\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.8955\n",
      "Epoch 00044: val_accuracy improved from 0.96296 to 0.97037, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.2714 - accuracy: 0.8955 - val_loss: 0.0976 - val_accuracy: 0.9704\n",
      "Epoch 45/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.9145\n",
      "Epoch 00045: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.2360 - accuracy: 0.9145 - val_loss: 0.1605 - val_accuracy: 0.9556\n",
      "Epoch 46/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.9082\n",
      "Epoch 00046: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2343 - accuracy: 0.9082 - val_loss: 0.1276 - val_accuracy: 0.9630\n",
      "Epoch 47/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2376 - accuracy: 0.9101\n",
      "Epoch 00047: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2376 - accuracy: 0.9101 - val_loss: 0.1496 - val_accuracy: 0.9481\n",
      "Epoch 48/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2396 - accuracy: 0.9113\n",
      "Epoch 00048: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2396 - accuracy: 0.9113 - val_loss: 0.1327 - val_accuracy: 0.9556\n",
      "Epoch 49/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9189\n",
      "Epoch 00049: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2055 - accuracy: 0.9189 - val_loss: 0.1722 - val_accuracy: 0.9333\n",
      "Epoch 50/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9215\n",
      "Epoch 00050: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2167 - accuracy: 0.9215 - val_loss: 0.1013 - val_accuracy: 0.9630\n",
      "Epoch 51/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.9259\n",
      "Epoch 00051: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2097 - accuracy: 0.9259 - val_loss: 0.1896 - val_accuracy: 0.9185\n",
      "Epoch 52/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.9234\n",
      "Epoch 00052: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2160 - accuracy: 0.9234 - val_loss: 0.1546 - val_accuracy: 0.9407\n",
      "Epoch 53/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.9120\n",
      "Epoch 00053: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2381 - accuracy: 0.9120 - val_loss: 0.1267 - val_accuracy: 0.9556\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.9151\n",
      "Epoch 00054: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2347 - accuracy: 0.9151 - val_loss: 0.1229 - val_accuracy: 0.9556\n",
      "Epoch 55/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9265\n",
      "Epoch 00055: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2193 - accuracy: 0.9265 - val_loss: 0.1322 - val_accuracy: 0.9556\n",
      "Epoch 56/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.9310\n",
      "Epoch 00056: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.1857 - accuracy: 0.9310 - val_loss: 0.1242 - val_accuracy: 0.9407\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9335\n",
      "Epoch 00057: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1885 - accuracy: 0.9335 - val_loss: 0.1320 - val_accuracy: 0.9630\n",
      "Epoch 58/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9291\n",
      "Epoch 00058: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1861 - accuracy: 0.9291 - val_loss: 0.1566 - val_accuracy: 0.9185\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.9284\n",
      "Epoch 00059: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2054 - accuracy: 0.9284 - val_loss: 0.1265 - val_accuracy: 0.9556\n",
      "Epoch 60/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9411\n",
      "Epoch 00060: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1896 - accuracy: 0.9411 - val_loss: 0.1278 - val_accuracy: 0.9407\n",
      "Epoch 61/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1657 - accuracy: 0.9417\n",
      "Epoch 00061: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1657 - accuracy: 0.9417 - val_loss: 0.0936 - val_accuracy: 0.9630\n",
      "Epoch 62/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9360\n",
      "Epoch 00062: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.1694 - accuracy: 0.9360 - val_loss: 0.1156 - val_accuracy: 0.9481\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.9284\n",
      "Epoch 00063: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1984 - accuracy: 0.9284 - val_loss: 0.1361 - val_accuracy: 0.9333\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1812 - accuracy: 0.9291\n",
      "Epoch 00064: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1812 - accuracy: 0.9291 - val_loss: 0.1079 - val_accuracy: 0.9704\n",
      "Epoch 65/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9411\n",
      "Epoch 00065: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1675 - accuracy: 0.9411 - val_loss: 0.1600 - val_accuracy: 0.9259\n",
      "Epoch 66/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.9291\n",
      "Epoch 00066: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.1792 - accuracy: 0.9291 - val_loss: 0.1061 - val_accuracy: 0.9704\n",
      "Epoch 67/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.9335\n",
      "Epoch 00067: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1841 - accuracy: 0.9335 - val_loss: 0.1844 - val_accuracy: 0.9111\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 0.9417\n",
      "Epoch 00068: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1668 - accuracy: 0.9417 - val_loss: 0.1274 - val_accuracy: 0.9407\n",
      "Epoch 69/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9405\n",
      "Epoch 00069: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1582 - accuracy: 0.9405 - val_loss: 0.0826 - val_accuracy: 0.9630\n",
      "Epoch 70/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.9335\n",
      "Epoch 00070: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1801 - accuracy: 0.9335 - val_loss: 0.0935 - val_accuracy: 0.9704\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 0.9329\n",
      "Epoch 00071: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1758 - accuracy: 0.9329 - val_loss: 0.1425 - val_accuracy: 0.9630\n",
      "Epoch 72/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9240\n",
      "Epoch 00072: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.2063 - accuracy: 0.9240 - val_loss: 0.1058 - val_accuracy: 0.9481\n",
      "Epoch 73/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9303\n",
      "Epoch 00073: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1928 - accuracy: 0.9303 - val_loss: 0.1102 - val_accuracy: 0.9481\n",
      "Epoch 74/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9493\n",
      "Epoch 00074: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.1434 - accuracy: 0.9493 - val_loss: 0.0915 - val_accuracy: 0.9704\n",
      "Epoch 75/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9576\n",
      "Epoch 00075: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.1403 - accuracy: 0.9576 - val_loss: 0.1704 - val_accuracy: 0.9111\n",
      "Epoch 76/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.9519\n",
      "Epoch 00076: val_accuracy did not improve from 0.97037\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.1389 - accuracy: 0.9519 - val_loss: 0.0609 - val_accuracy: 0.9704\n",
      "Epoch 77/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.9436\n",
      "Epoch 00077: val_accuracy improved from 0.97037 to 0.97778, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.1508 - accuracy: 0.9436 - val_loss: 0.0691 - val_accuracy: 0.9778\n",
      "Epoch 78/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9398\n",
      "Epoch 00078: val_accuracy improved from 0.97778 to 0.98519, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.1620 - accuracy: 0.9398 - val_loss: 0.0501 - val_accuracy: 0.9852\n",
      "Epoch 79/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.9398\n",
      "Epoch 00079: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.1683 - accuracy: 0.9398 - val_loss: 0.0622 - val_accuracy: 0.9852\n",
      "Epoch 80/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9474\n",
      "Epoch 00080: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.1405 - accuracy: 0.9474 - val_loss: 0.1915 - val_accuracy: 0.9259\n",
      "Epoch 81/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9284\n",
      "Epoch 00081: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.1723 - accuracy: 0.9284 - val_loss: 0.0780 - val_accuracy: 0.9704\n",
      "Epoch 82/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9500\n",
      "Epoch 00082: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.1216 - accuracy: 0.9500 - val_loss: 0.0890 - val_accuracy: 0.9704\n",
      "Epoch 83/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.9506\n",
      "Epoch 00083: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 71s 1s/step - loss: 0.1348 - accuracy: 0.9506 - val_loss: 0.0719 - val_accuracy: 0.9704\n",
      "Epoch 84/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.9519\n",
      "Epoch 00084: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1278 - accuracy: 0.9519 - val_loss: 0.0609 - val_accuracy: 0.9852\n",
      "Epoch 85/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1621 - accuracy: 0.9398\n",
      "Epoch 00085: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1621 - accuracy: 0.9398 - val_loss: 0.1109 - val_accuracy: 0.9630\n",
      "Epoch 86/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.9449\n",
      "Epoch 00086: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1511 - accuracy: 0.9449 - val_loss: 0.0720 - val_accuracy: 0.9778\n",
      "Epoch 87/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9436\n",
      "Epoch 00087: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1628 - accuracy: 0.9436 - val_loss: 0.1598 - val_accuracy: 0.9259\n",
      "Epoch 88/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1581 - accuracy: 0.9474\n",
      "Epoch 00088: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1581 - accuracy: 0.9474 - val_loss: 0.1124 - val_accuracy: 0.9556\n",
      "Epoch 89/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.9481\n",
      "Epoch 00089: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1378 - accuracy: 0.9481 - val_loss: 0.0878 - val_accuracy: 0.9556\n",
      "Epoch 90/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9455\n",
      "Epoch 00090: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1417 - accuracy: 0.9455 - val_loss: 0.1536 - val_accuracy: 0.9259\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.9512\n",
      "Epoch 00091: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1290 - accuracy: 0.9512 - val_loss: 0.0494 - val_accuracy: 0.9852\n",
      "Epoch 92/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9550\n",
      "Epoch 00092: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1283 - accuracy: 0.9550 - val_loss: 0.0734 - val_accuracy: 0.9704\n",
      "Epoch 93/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9474\n",
      "Epoch 00093: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1569 - accuracy: 0.9474 - val_loss: 0.1310 - val_accuracy: 0.9556\n",
      "Epoch 94/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.9557\n",
      "Epoch 00094: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1345 - accuracy: 0.9557 - val_loss: 0.0617 - val_accuracy: 0.9778\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9531\n",
      "Epoch 00095: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1341 - accuracy: 0.9531 - val_loss: 0.0914 - val_accuracy: 0.9481\n",
      "Epoch 96/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9487\n",
      "Epoch 00096: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1478 - accuracy: 0.9487 - val_loss: 0.1593 - val_accuracy: 0.9185\n",
      "Epoch 97/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9588\n",
      "Epoch 00097: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1219 - accuracy: 0.9588 - val_loss: 0.0520 - val_accuracy: 0.9852\n",
      "Epoch 98/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9563\n",
      "Epoch 00098: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1138 - accuracy: 0.9563 - val_loss: 0.1116 - val_accuracy: 0.9333\n",
      "Epoch 99/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9607\n",
      "Epoch 00099: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1107 - accuracy: 0.9607 - val_loss: 0.0776 - val_accuracy: 0.9630\n",
      "Epoch 100/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.9569\n",
      "Epoch 00100: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1122 - accuracy: 0.9569 - val_loss: 0.0656 - val_accuracy: 0.9704\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.9436\n",
      "Epoch 00101: val_accuracy did not improve from 0.98519\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.1680 - accuracy: 0.9436 - val_loss: 0.0857 - val_accuracy: 0.9630\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9633\n",
      "Epoch 00102: val_accuracy improved from 0.98519 to 0.99259, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.1107 - accuracy: 0.9633 - val_loss: 0.0481 - val_accuracy: 0.9926\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9582\n",
      "Epoch 00103: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1022 - accuracy: 0.9582 - val_loss: 0.1105 - val_accuracy: 0.9481\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.9531\n",
      "Epoch 00104: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1308 - accuracy: 0.9531 - val_loss: 0.0775 - val_accuracy: 0.9704\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9563\n",
      "Epoch 00105: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.1162 - accuracy: 0.9563 - val_loss: 0.0942 - val_accuracy: 0.9556\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9595\n",
      "Epoch 00106: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1060 - accuracy: 0.9595 - val_loss: 0.0674 - val_accuracy: 0.9778\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.9582\n",
      "Epoch 00107: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1054 - accuracy: 0.9582 - val_loss: 0.0585 - val_accuracy: 0.9778\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9544\n",
      "Epoch 00108: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1157 - accuracy: 0.9544 - val_loss: 0.0726 - val_accuracy: 0.9704\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.9576\n",
      "Epoch 00109: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1187 - accuracy: 0.9576 - val_loss: 0.0621 - val_accuracy: 0.9704\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9576\n",
      "Epoch 00110: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.1102 - accuracy: 0.9576 - val_loss: 0.0502 - val_accuracy: 0.9852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9645\n",
      "Epoch 00111: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1129 - accuracy: 0.9645 - val_loss: 0.0458 - val_accuracy: 0.9852\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.9455\n",
      "Epoch 00112: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1550 - accuracy: 0.9455 - val_loss: 0.0662 - val_accuracy: 0.9630\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9690\n",
      "Epoch 00113: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1084 - accuracy: 0.9690 - val_loss: 0.1009 - val_accuracy: 0.9556\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9576\n",
      "Epoch 00114: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1097 - accuracy: 0.9576 - val_loss: 0.0843 - val_accuracy: 0.9481\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.9474\n",
      "Epoch 00115: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1499 - accuracy: 0.9474 - val_loss: 0.0870 - val_accuracy: 0.9704\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.9525\n",
      "Epoch 00116: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1337 - accuracy: 0.9525 - val_loss: 0.1003 - val_accuracy: 0.9704\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9557\n",
      "Epoch 00117: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1238 - accuracy: 0.9557 - val_loss: 0.0989 - val_accuracy: 0.9704\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.9626\n",
      "Epoch 00118: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1045 - accuracy: 0.9626 - val_loss: 0.0640 - val_accuracy: 0.9852\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9614\n",
      "Epoch 00119: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1008 - accuracy: 0.9614 - val_loss: 0.0547 - val_accuracy: 0.9926\n",
      "Epoch 120/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.9557\n",
      "Epoch 00120: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1199 - accuracy: 0.9557 - val_loss: 0.0876 - val_accuracy: 0.9704\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9677\n",
      "Epoch 00121: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0935 - accuracy: 0.9677 - val_loss: 0.0552 - val_accuracy: 0.9852\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.9690\n",
      "Epoch 00122: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0964 - accuracy: 0.9690 - val_loss: 0.0919 - val_accuracy: 0.9556\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9588\n",
      "Epoch 00123: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1030 - accuracy: 0.9588 - val_loss: 0.0690 - val_accuracy: 0.9778\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9607\n",
      "Epoch 00124: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0999 - accuracy: 0.9607 - val_loss: 0.1040 - val_accuracy: 0.9481\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9607\n",
      "Epoch 00125: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1173 - accuracy: 0.9607 - val_loss: 0.0963 - val_accuracy: 0.9556\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9709\n",
      "Epoch 00126: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0739 - accuracy: 0.9709 - val_loss: 0.1150 - val_accuracy: 0.9481\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9797\n",
      "Epoch 00127: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0668 - accuracy: 0.9797 - val_loss: 0.0481 - val_accuracy: 0.9926\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9620\n",
      "Epoch 00128: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1008 - accuracy: 0.9620 - val_loss: 0.0755 - val_accuracy: 0.9704\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9740\n",
      "Epoch 00129: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0736 - accuracy: 0.9740 - val_loss: 0.1657 - val_accuracy: 0.9185\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9633\n",
      "Epoch 00130: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0953 - accuracy: 0.9633 - val_loss: 0.1738 - val_accuracy: 0.9185\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9702\n",
      "Epoch 00131: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0967 - accuracy: 0.9702 - val_loss: 0.0735 - val_accuracy: 0.9778\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9645\n",
      "Epoch 00132: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0865 - accuracy: 0.9645 - val_loss: 0.0872 - val_accuracy: 0.9704\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9506\n",
      "Epoch 00133: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1351 - accuracy: 0.9506 - val_loss: 0.1096 - val_accuracy: 0.9407\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.9607\n",
      "Epoch 00134: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1062 - accuracy: 0.9607 - val_loss: 0.0562 - val_accuracy: 0.9852\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9614\n",
      "Epoch 00135: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0908 - accuracy: 0.9614 - val_loss: 0.0983 - val_accuracy: 0.9481\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9740\n",
      "Epoch 00136: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0746 - accuracy: 0.9740 - val_loss: 0.0579 - val_accuracy: 0.9704\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9569\n",
      "Epoch 00137: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1182 - accuracy: 0.9569 - val_loss: 0.0370 - val_accuracy: 0.9852\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9702\n",
      "Epoch 00138: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0897 - accuracy: 0.9702 - val_loss: 0.0721 - val_accuracy: 0.9630\n",
      "Epoch 139/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9759\n",
      "Epoch 00139: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0742 - accuracy: 0.9759 - val_loss: 0.0722 - val_accuracy: 0.9704\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9639\n",
      "Epoch 00140: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1069 - accuracy: 0.9639 - val_loss: 0.0592 - val_accuracy: 0.9852\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9690\n",
      "Epoch 00141: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0949 - accuracy: 0.9690 - val_loss: 0.0524 - val_accuracy: 0.9630\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9607\n",
      "Epoch 00142: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1252 - accuracy: 0.9607 - val_loss: 0.0270 - val_accuracy: 0.9852\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.9702\n",
      "Epoch 00143: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0868 - accuracy: 0.9702 - val_loss: 0.1029 - val_accuracy: 0.9556\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9721\n",
      "Epoch 00144: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0832 - accuracy: 0.9721 - val_loss: 0.2055 - val_accuracy: 0.9333\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 0.9652\n",
      "Epoch 00145: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1113 - accuracy: 0.9652 - val_loss: 0.0820 - val_accuracy: 0.9778\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.9544\n",
      "Epoch 00146: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1505 - accuracy: 0.9544 - val_loss: 0.0515 - val_accuracy: 0.9852\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.9620\n",
      "Epoch 00147: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0958 - accuracy: 0.9620 - val_loss: 0.0869 - val_accuracy: 0.9630\n",
      "Epoch 148/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9620\n",
      "Epoch 00148: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1051 - accuracy: 0.9620 - val_loss: 0.0560 - val_accuracy: 0.9852\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.9633\n",
      "Epoch 00149: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0890 - accuracy: 0.9633 - val_loss: 0.1234 - val_accuracy: 0.9556\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.9759\n",
      "Epoch 00150: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0729 - accuracy: 0.9759 - val_loss: 0.0479 - val_accuracy: 0.9852\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9696\n",
      "Epoch 00151: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0879 - accuracy: 0.9696 - val_loss: 0.0518 - val_accuracy: 0.9778\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.9525\n",
      "Epoch 00152: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1129 - accuracy: 0.9525 - val_loss: 0.0375 - val_accuracy: 0.9778\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9747\n",
      "Epoch 00153: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0736 - accuracy: 0.9747 - val_loss: 0.0843 - val_accuracy: 0.9630\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9645\n",
      "Epoch 00154: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0973 - accuracy: 0.9645 - val_loss: 0.0479 - val_accuracy: 0.9852\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.9677\n",
      "Epoch 00155: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.0895 - accuracy: 0.9677 - val_loss: 0.0460 - val_accuracy: 0.9778\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9702\n",
      "Epoch 00156: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0839 - accuracy: 0.9702 - val_loss: 0.0603 - val_accuracy: 0.9778\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.9645\n",
      "Epoch 00157: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.0988 - accuracy: 0.9645 - val_loss: 0.0571 - val_accuracy: 0.9778\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9626\n",
      "Epoch 00158: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0907 - accuracy: 0.9626 - val_loss: 0.0411 - val_accuracy: 0.9926\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9690\n",
      "Epoch 00159: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0787 - accuracy: 0.9690 - val_loss: 0.0642 - val_accuracy: 0.9778\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9753\n",
      "Epoch 00160: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0678 - accuracy: 0.9753 - val_loss: 0.0862 - val_accuracy: 0.9556\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9702\n",
      "Epoch 00161: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0827 - accuracy: 0.9702 - val_loss: 0.0518 - val_accuracy: 0.9778\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9759\n",
      "Epoch 00162: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0707 - accuracy: 0.9759 - val_loss: 0.0463 - val_accuracy: 0.9852\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9677\n",
      "Epoch 00163: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1083 - accuracy: 0.9677 - val_loss: 0.0363 - val_accuracy: 0.9852\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9671\n",
      "Epoch 00164: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0898 - accuracy: 0.9671 - val_loss: 0.1443 - val_accuracy: 0.9407\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9785\n",
      "Epoch 00165: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0723 - accuracy: 0.9785 - val_loss: 0.2118 - val_accuracy: 0.9259\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.9658\n",
      "Epoch 00166: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1042 - accuracy: 0.9658 - val_loss: 0.1135 - val_accuracy: 0.9481\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9785\n",
      "Epoch 00167: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0704 - accuracy: 0.9785 - val_loss: 0.0522 - val_accuracy: 0.9852\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9747\n",
      "Epoch 00168: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0754 - accuracy: 0.9747 - val_loss: 0.3209 - val_accuracy: 0.9037\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9588\n",
      "Epoch 00169: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1066 - accuracy: 0.9588 - val_loss: 0.0504 - val_accuracy: 0.9852\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9728\n",
      "Epoch 00170: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0737 - accuracy: 0.9728 - val_loss: 0.0445 - val_accuracy: 0.9778\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 0.9747\n",
      "Epoch 00171: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0796 - accuracy: 0.9747 - val_loss: 0.1108 - val_accuracy: 0.9407\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.9715\n",
      "Epoch 00172: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0850 - accuracy: 0.9715 - val_loss: 0.0795 - val_accuracy: 0.9704\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9696\n",
      "Epoch 00173: val_accuracy did not improve from 0.99259\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0766 - accuracy: 0.9696 - val_loss: 0.0537 - val_accuracy: 0.9778\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.9766\n",
      "Epoch 00174: val_accuracy improved from 0.99259 to 1.00000, saving model to E:\\Cotton Leaf Disease Detection\\model\n",
      "INFO:tensorflow:Assets written to: E:\\Cotton Leaf Disease Detection\\model\\assets\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0708 - accuracy: 0.9766 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9747\n",
      "Epoch 00175: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.0672 - accuracy: 0.9747 - val_loss: 0.0886 - val_accuracy: 0.9704\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.9766\n",
      "Epoch 00176: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0757 - accuracy: 0.9766 - val_loss: 0.0802 - val_accuracy: 0.9630\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9734\n",
      "Epoch 00177: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0828 - accuracy: 0.9734 - val_loss: 0.0426 - val_accuracy: 0.9926\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9607\n",
      "Epoch 00178: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.1028 - accuracy: 0.9607 - val_loss: 0.0517 - val_accuracy: 0.9778\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9740\n",
      "Epoch 00179: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0778 - accuracy: 0.9740 - val_loss: 0.0282 - val_accuracy: 0.9926\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9728\n",
      "Epoch 00180: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0798 - accuracy: 0.9728 - val_loss: 0.0413 - val_accuracy: 0.9778\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9709\n",
      "Epoch 00181: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0725 - accuracy: 0.9709 - val_loss: 0.0786 - val_accuracy: 0.9556\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9671\n",
      "Epoch 00182: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0824 - accuracy: 0.9671 - val_loss: 0.0561 - val_accuracy: 0.9704\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9696\n",
      "Epoch 00183: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0951 - accuracy: 0.9696 - val_loss: 0.1042 - val_accuracy: 0.9630\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9797\n",
      "Epoch 00184: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0602 - accuracy: 0.9797 - val_loss: 0.0857 - val_accuracy: 0.9630\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9677\n",
      "Epoch 00185: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0798 - accuracy: 0.9677 - val_loss: 0.0284 - val_accuracy: 0.9926\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9816\n",
      "Epoch 00186: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0501 - accuracy: 0.9816 - val_loss: 0.0345 - val_accuracy: 0.9926\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 0.9778\n",
      "Epoch 00187: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.0589 - accuracy: 0.9778 - val_loss: 0.0468 - val_accuracy: 0.9778\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.9728\n",
      "Epoch 00188: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0776 - accuracy: 0.9728 - val_loss: 0.0503 - val_accuracy: 0.9852\n",
      "Epoch 189/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9702\n",
      "Epoch 00189: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0828 - accuracy: 0.9702 - val_loss: 0.0467 - val_accuracy: 0.9852\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.9747\n",
      "Epoch 00190: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0741 - accuracy: 0.9747 - val_loss: 0.0525 - val_accuracy: 0.9778\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9690\n",
      "Epoch 00191: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0786 - accuracy: 0.9690 - val_loss: 0.1112 - val_accuracy: 0.9630\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9766\n",
      "Epoch 00192: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0671 - accuracy: 0.9766 - val_loss: 0.0913 - val_accuracy: 0.9630\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9677\n",
      "Epoch 00193: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0863 - accuracy: 0.9677 - val_loss: 0.0775 - val_accuracy: 0.9630\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9721\n",
      "Epoch 00194: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0751 - accuracy: 0.9721 - val_loss: 0.0605 - val_accuracy: 0.9778\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9804\n",
      "Epoch 00195: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0622 - accuracy: 0.9804 - val_loss: 0.0307 - val_accuracy: 0.9852\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9797\n",
      "Epoch 00196: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0562 - accuracy: 0.9797 - val_loss: 0.0553 - val_accuracy: 0.9704\n",
      "Epoch 197/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9785\n",
      "Epoch 00197: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0703 - accuracy: 0.9785 - val_loss: 0.0654 - val_accuracy: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9797\n",
      "Epoch 00198: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0601 - accuracy: 0.9797 - val_loss: 0.0497 - val_accuracy: 0.9778\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9753\n",
      "Epoch 00199: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 69s 1s/step - loss: 0.0695 - accuracy: 0.9753 - val_loss: 0.0641 - val_accuracy: 0.9778\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9804\n",
      "Epoch 00200: val_accuracy did not improve from 1.00000\n",
      "50/50 [==============================] - 70s 1s/step - loss: 0.0650 - accuracy: 0.9804 - val_loss: 0.0460 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "# train cnn model\n",
    "history = cnn_model.fit(training_data, \n",
    "                          epochs=200, \n",
    "                          verbose=1, \n",
    "                          validation_data= valid_data,\n",
    "                          callbacks=callbacks_list) # time start 16.06\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303fa85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a95f907c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# summarize history for accuracy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "feb8aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "cnn_model.save('model_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eb84b7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2294327 , 0.27067316, 0.2788886 , 0.2210055 ],\n",
       "       [0.2306738 , 0.2635709 , 0.2777627 , 0.22799264],\n",
       "       [0.22565506, 0.2712699 , 0.2810822 , 0.22199287],\n",
       "       [0.23299628, 0.28545743, 0.26703712, 0.21450919],\n",
       "       [0.22779572, 0.2721831 , 0.27177754, 0.22824363],\n",
       "       [0.21886362, 0.27717462, 0.2756006 , 0.22836111],\n",
       "       [0.23447579, 0.2727026 , 0.26934856, 0.2234731 ],\n",
       "       [0.22719948, 0.28265986, 0.27811363, 0.21202704],\n",
       "       [0.23224404, 0.2821517 , 0.2681974 , 0.21740688],\n",
       "       [0.22469705, 0.2838863 , 0.27185988, 0.21955673],\n",
       "       [0.23786074, 0.26561734, 0.27687532, 0.21964663],\n",
       "       [0.2333323 , 0.27284187, 0.27419385, 0.21963198],\n",
       "       [0.2310848 , 0.28016663, 0.26751146, 0.22123711],\n",
       "       [0.23011579, 0.2741043 , 0.2673934 , 0.22838657],\n",
       "       [0.23470068, 0.27400285, 0.2653729 , 0.22592358],\n",
       "       [0.22309738, 0.28161216, 0.27187076, 0.22341974],\n",
       "       [0.23116845, 0.2780612 , 0.27095962, 0.21981068],\n",
       "       [0.21368586, 0.29592013, 0.27012664, 0.22026744],\n",
       "       [0.2247221 , 0.27692434, 0.28161085, 0.21674272],\n",
       "       [0.22871827, 0.27574202, 0.27949977, 0.21603988],\n",
       "       [0.22997212, 0.27335727, 0.2700127 , 0.22665784],\n",
       "       [0.22732966, 0.27785298, 0.2726865 , 0.22213088],\n",
       "       [0.23665461, 0.26577142, 0.26387805, 0.23369597],\n",
       "       [0.22472699, 0.27284607, 0.27683765, 0.22558925],\n",
       "       [0.23202085, 0.28562003, 0.26774848, 0.21461062],\n",
       "       [0.23316532, 0.2656478 , 0.28969488, 0.21149196],\n",
       "       [0.22718757, 0.2757312 , 0.265599  , 0.23148225],\n",
       "       [0.22519831, 0.2805216 , 0.2741846 , 0.22009543],\n",
       "       [0.22309004, 0.27345774, 0.27508315, 0.22836907],\n",
       "       [0.23335163, 0.27806452, 0.2698075 , 0.21877635],\n",
       "       [0.23234238, 0.25993145, 0.28040886, 0.22731732],\n",
       "       [0.23548989, 0.27480635, 0.27509168, 0.21461205],\n",
       "       [0.23226379, 0.27493426, 0.2685261 , 0.22427586],\n",
       "       [0.22678474, 0.27466008, 0.27985135, 0.21870384],\n",
       "       [0.22711891, 0.2728677 , 0.27283293, 0.22718045],\n",
       "       [0.22882856, 0.28566805, 0.2527871 , 0.23271629],\n",
       "       [0.24021676, 0.28084442, 0.2633829 , 0.21555594],\n",
       "       [0.22923331, 0.2709547 , 0.27925885, 0.22055314],\n",
       "       [0.23767982, 0.27803776, 0.2769483 , 0.20733404],\n",
       "       [0.22649488, 0.27795798, 0.27845433, 0.21709278],\n",
       "       [0.21525562, 0.28197494, 0.27897888, 0.22379057],\n",
       "       [0.23014498, 0.27778736, 0.27306   , 0.21900766],\n",
       "       [0.23578921, 0.27670693, 0.26657858, 0.22092526],\n",
       "       [0.22830743, 0.26856664, 0.27679935, 0.22632658],\n",
       "       [0.23533347, 0.26243663, 0.27906942, 0.22316049],\n",
       "       [0.23359011, 0.27198532, 0.2675132 , 0.22691134],\n",
       "       [0.22878648, 0.2675472 , 0.2783031 , 0.22536322],\n",
       "       [0.24228704, 0.2710258 , 0.26442838, 0.22225875],\n",
       "       [0.2350698 , 0.28867176, 0.27313805, 0.2031204 ],\n",
       "       [0.20652755, 0.28927276, 0.2782855 , 0.22591415],\n",
       "       [0.2223417 , 0.28106752, 0.27892995, 0.21766084],\n",
       "       [0.23570582, 0.27390656, 0.2752321 , 0.21515553],\n",
       "       [0.22714227, 0.27370664, 0.27475592, 0.22439516],\n",
       "       [0.23360316, 0.27230552, 0.28276953, 0.21132185],\n",
       "       [0.22882213, 0.28497964, 0.25602686, 0.23017134],\n",
       "       [0.21724148, 0.27289778, 0.27362332, 0.2362374 ],\n",
       "       [0.22837268, 0.26227275, 0.27964896, 0.22970562],\n",
       "       [0.22822127, 0.27982518, 0.27799726, 0.21395633],\n",
       "       [0.22868049, 0.2832505 , 0.27361187, 0.21445714],\n",
       "       [0.23435543, 0.26973176, 0.2743716 , 0.2215412 ],\n",
       "       [0.23112826, 0.26896232, 0.27315012, 0.22675928],\n",
       "       [0.21897735, 0.2695491 , 0.27282056, 0.23865299],\n",
       "       [0.2303181 , 0.25963336, 0.27335024, 0.2366983 ],\n",
       "       [0.2350079 , 0.27740458, 0.27629235, 0.21129517],\n",
       "       [0.23453778, 0.27155972, 0.27543208, 0.21847044],\n",
       "       [0.22363251, 0.28064084, 0.27356738, 0.22215925],\n",
       "       [0.22847524, 0.2727349 , 0.27682948, 0.22196032],\n",
       "       [0.22833455, 0.27450618, 0.28224438, 0.21491483],\n",
       "       [0.22250949, 0.26901996, 0.28531912, 0.2231514 ],\n",
       "       [0.22940655, 0.27595928, 0.2807807 , 0.21385345],\n",
       "       [0.23250216, 0.26887396, 0.27316555, 0.2254583 ],\n",
       "       [0.2322117 , 0.2736991 , 0.27697292, 0.21711631],\n",
       "       [0.2401447 , 0.26694515, 0.26870078, 0.22420944],\n",
       "       [0.22299501, 0.2794825 , 0.26859066, 0.22893189],\n",
       "       [0.24173312, 0.27083445, 0.27478537, 0.21264702],\n",
       "       [0.22574922, 0.27591544, 0.27433488, 0.22400047],\n",
       "       [0.22919375, 0.28513277, 0.27510044, 0.21057314],\n",
       "       [0.22041541, 0.28531525, 0.27662516, 0.21764421],\n",
       "       [0.21791478, 0.2914666 , 0.283077  , 0.20754166],\n",
       "       [0.22430976, 0.27161208, 0.27476278, 0.22931537],\n",
       "       [0.233728  , 0.2866442 , 0.2726761 , 0.20695175],\n",
       "       [0.24238178, 0.26633388, 0.26425403, 0.22703037],\n",
       "       [0.23007002, 0.28432503, 0.27753347, 0.20807149],\n",
       "       [0.22564296, 0.28150198, 0.26643732, 0.22641772],\n",
       "       [0.23608398, 0.2765558 , 0.26694164, 0.2204186 ],\n",
       "       [0.22738685, 0.27366424, 0.27055103, 0.22839785],\n",
       "       [0.22883834, 0.26745778, 0.27117428, 0.23252961],\n",
       "       [0.2301321 , 0.26436734, 0.27761194, 0.22788867],\n",
       "       [0.23442033, 0.27603593, 0.27644408, 0.21309972],\n",
       "       [0.2436537 , 0.26967445, 0.25717646, 0.22949532],\n",
       "       [0.22895935, 0.27219507, 0.2867868 , 0.21205877],\n",
       "       [0.22791441, 0.27624822, 0.2702941 , 0.22554329],\n",
       "       [0.22958927, 0.26277995, 0.27710298, 0.23052771],\n",
       "       [0.22867662, 0.27151603, 0.27550006, 0.22430727],\n",
       "       [0.23567788, 0.28119054, 0.25825495, 0.22487658],\n",
       "       [0.23406348, 0.274192  , 0.2789593 , 0.21278524],\n",
       "       [0.21629247, 0.27144146, 0.2753691 , 0.23689693],\n",
       "       [0.2275393 , 0.27208027, 0.277045  , 0.22333536],\n",
       "       [0.23095368, 0.26908094, 0.27114266, 0.22882272],\n",
       "       [0.23262529, 0.27954683, 0.27055967, 0.21726815],\n",
       "       [0.22862753, 0.27799234, 0.27660736, 0.21677274],\n",
       "       [0.22532143, 0.27658153, 0.26908475, 0.22901228],\n",
       "       [0.22003664, 0.27839604, 0.26792067, 0.23364665],\n",
       "       [0.24353667, 0.25971675, 0.26840162, 0.22834502],\n",
       "       [0.23475005, 0.27986112, 0.2741302 , 0.2112587 ],\n",
       "       [0.2309915 , 0.27146325, 0.27360696, 0.2239383 ],\n",
       "       [0.22188626, 0.26902634, 0.27578261, 0.23330481],\n",
       "       [0.23820186, 0.27721292, 0.2748016 , 0.2097836 ],\n",
       "       [0.22442305, 0.28095955, 0.27093548, 0.22368188],\n",
       "       [0.23179305, 0.28613028, 0.27823672, 0.20383993],\n",
       "       [0.22378121, 0.28329057, 0.27733457, 0.21559365],\n",
       "       [0.23102072, 0.2745241 , 0.2632422 , 0.23121296],\n",
       "       [0.22977757, 0.28561416, 0.27163637, 0.21297191],\n",
       "       [0.23550236, 0.27436063, 0.271271  , 0.21886599],\n",
       "       [0.23205169, 0.27106875, 0.2730243 , 0.2238553 ],\n",
       "       [0.2313237 , 0.29271576, 0.27185723, 0.20410338],\n",
       "       [0.23016144, 0.27521014, 0.2750489 , 0.21957944],\n",
       "       [0.23034114, 0.27119958, 0.27415264, 0.22430661],\n",
       "       [0.22837925, 0.25917128, 0.28116322, 0.23128627],\n",
       "       [0.23807734, 0.2747954 , 0.26883432, 0.21829286],\n",
       "       [0.23413919, 0.27098384, 0.2719859 , 0.22289102],\n",
       "       [0.22434281, 0.2876024 , 0.26718357, 0.22087125],\n",
       "       [0.22432049, 0.27051383, 0.2752216 , 0.22994408],\n",
       "       [0.23173776, 0.2715973 , 0.26751494, 0.22915006],\n",
       "       [0.23356523, 0.27741888, 0.26617727, 0.22283866],\n",
       "       [0.2227665 , 0.2878188 , 0.27352744, 0.21588731],\n",
       "       [0.23271728, 0.26401904, 0.26957804, 0.23368561],\n",
       "       [0.2331689 , 0.27275285, 0.27838874, 0.21568954],\n",
       "       [0.21441041, 0.28098172, 0.2790553 , 0.2255526 ],\n",
       "       [0.22525442, 0.2777222 , 0.27520344, 0.22182001],\n",
       "       [0.22856143, 0.27796993, 0.2624874 , 0.2309812 ],\n",
       "       [0.23782793, 0.26550174, 0.26953107, 0.22713925],\n",
       "       [0.2251644 , 0.2844197 , 0.28532848, 0.2050874 ],\n",
       "       [0.2275268 , 0.27418822, 0.27158755, 0.22669742],\n",
       "       [0.22687525, 0.26792517, 0.274039  , 0.23116066],\n",
       "       [0.23483326, 0.27295086, 0.26845598, 0.22375992],\n",
       "       [0.22525907, 0.2800409 , 0.2897107 , 0.20498933],\n",
       "       [0.23034666, 0.26860586, 0.27216533, 0.22888213],\n",
       "       [0.23941128, 0.26949096, 0.26751527, 0.22358252],\n",
       "       [0.2257401 , 0.27447703, 0.2862579 , 0.21352492],\n",
       "       [0.23361146, 0.26286912, 0.2804491 , 0.22307025],\n",
       "       [0.23033436, 0.283294  , 0.27228323, 0.21408845],\n",
       "       [0.22775216, 0.2742839 , 0.28040838, 0.21755552],\n",
       "       [0.2354919 , 0.28290555, 0.2623999 , 0.21920262],\n",
       "       [0.22783555, 0.292235  , 0.26649106, 0.21343832],\n",
       "       [0.24081741, 0.26548684, 0.27250615, 0.22118956],\n",
       "       [0.23970637, 0.27126372, 0.27196628, 0.2170636 ],\n",
       "       [0.23445196, 0.27359575, 0.2701578 , 0.22179437],\n",
       "       [0.22747938, 0.28270504, 0.27061838, 0.21919721],\n",
       "       [0.23912352, 0.27217802, 0.26136175, 0.22733669],\n",
       "       [0.23253101, 0.27626342, 0.25997123, 0.23123431],\n",
       "       [0.22912422, 0.2833397 , 0.2704016 , 0.21713448],\n",
       "       [0.23111413, 0.2717295 , 0.28464025, 0.21251614],\n",
       "       [0.23196311, 0.2736921 , 0.26889458, 0.22545014],\n",
       "       [0.22602208, 0.27204764, 0.2838777 , 0.21805254],\n",
       "       [0.23734395, 0.25441703, 0.28009868, 0.22814031],\n",
       "       [0.2381249 , 0.26414904, 0.26448566, 0.23324044],\n",
       "       [0.22646105, 0.27511194, 0.27926958, 0.21915746],\n",
       "       [0.22344886, 0.27147433, 0.27916223, 0.22591461],\n",
       "       [0.23437679, 0.27701083, 0.27286625, 0.21574607],\n",
       "       [0.23493688, 0.25533468, 0.27243936, 0.2372891 ],\n",
       "       [0.23964442, 0.27282503, 0.26169664, 0.22583391],\n",
       "       [0.22684807, 0.2713848 , 0.27573976, 0.22602738],\n",
       "       [0.21859439, 0.2689702 , 0.27776915, 0.23466635],\n",
       "       [0.23032752, 0.27194685, 0.27364263, 0.22408307],\n",
       "       [0.23238973, 0.27577758, 0.26830757, 0.22352514],\n",
       "       [0.22860925, 0.27313247, 0.27606812, 0.2221902 ],\n",
       "       [0.23262353, 0.27176622, 0.27806395, 0.21754625],\n",
       "       [0.21845381, 0.28486106, 0.26597404, 0.23071107],\n",
       "       [0.22245632, 0.28063148, 0.27538732, 0.22152483],\n",
       "       [0.22075045, 0.2817564 , 0.27856866, 0.2189245 ],\n",
       "       [0.23293723, 0.25852323, 0.27822953, 0.23031   ],\n",
       "       [0.23150957, 0.26782525, 0.27918246, 0.22148266],\n",
       "       [0.2150873 , 0.27056283, 0.2822098 , 0.23214003],\n",
       "       [0.23409481, 0.2770128 , 0.2748814 , 0.21401106],\n",
       "       [0.23134379, 0.27480045, 0.27028802, 0.22356774],\n",
       "       [0.22175875, 0.2846546 , 0.27293018, 0.22065644],\n",
       "       [0.2307921 , 0.28293413, 0.2711398 , 0.21513402],\n",
       "       [0.22248651, 0.26689386, 0.28640774, 0.22421187],\n",
       "       [0.21970151, 0.27180004, 0.2778322 , 0.23066622],\n",
       "       [0.23361069, 0.2699581 , 0.27790928, 0.21852194],\n",
       "       [0.22258016, 0.2733877 , 0.27989283, 0.22413932],\n",
       "       [0.23794346, 0.27468175, 0.27276382, 0.21461093],\n",
       "       [0.22420608, 0.28003114, 0.27745008, 0.21831274],\n",
       "       [0.23087755, 0.26333922, 0.2781926 , 0.22759062],\n",
       "       [0.2423938 , 0.26482227, 0.27555853, 0.2172254 ],\n",
       "       [0.2249304 , 0.28266144, 0.26672858, 0.22567955],\n",
       "       [0.2348974 , 0.28022578, 0.2687586 , 0.21611829],\n",
       "       [0.23102765, 0.27676105, 0.2691401 , 0.22307113],\n",
       "       [0.23226379, 0.27493426, 0.2685261 , 0.22427586],\n",
       "       [0.2301172 , 0.28577265, 0.2585697 , 0.22554052],\n",
       "       [0.23135446, 0.28045994, 0.27827537, 0.20991018],\n",
       "       [0.23237933, 0.2667853 , 0.2839505 , 0.21688491],\n",
       "       [0.22767514, 0.28046867, 0.2804815 , 0.21137473],\n",
       "       [0.22799554, 0.27192128, 0.27772716, 0.22235596],\n",
       "       [0.2394406 , 0.2612645 , 0.26914227, 0.23015262],\n",
       "       [0.2369215 , 0.2649361 , 0.2656833 , 0.23245907],\n",
       "       [0.23722245, 0.2791994 , 0.26564503, 0.21793312],\n",
       "       [0.23712333, 0.27741006, 0.2684576 , 0.21700902],\n",
       "       [0.22492717, 0.28446326, 0.2644314 , 0.2261782 ],\n",
       "       [0.2352748 , 0.27287614, 0.2729362 , 0.21891284],\n",
       "       [0.22787908, 0.27837735, 0.27704415, 0.21669942],\n",
       "       [0.23604715, 0.2631257 , 0.26894668, 0.23188049],\n",
       "       [0.23411418, 0.2820055 , 0.2617385 , 0.22214182]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=cnn_model.predict(valid_data)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c39f51e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1,\n",
       "       1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2,\n",
       "       2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2,\n",
       "       2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1,\n",
       "       2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1,\n",
       "       1, 1, 2, 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f74dfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.1680733e-05, 3.8165108e-05, 9.8068523e-01, 1.9264869e-02],\n",
       "       [4.3255810e-07, 4.2142133e-08, 9.4120836e-01, 5.8791116e-02],\n",
       "       [1.0000000e+00, 1.4657064e-08, 1.3776076e-12, 3.0745444e-09],\n",
       "       ...,\n",
       "       [9.9986565e-01, 1.1940865e-06, 1.9081548e-05, 1.1401130e-04],\n",
       "       [9.5958436e-01, 5.1023248e-03, 2.9439034e-02, 5.8742464e-03],\n",
       "       [9.0983796e-01, 8.3492085e-02, 2.1656903e-03, 4.5043142e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred=cnn_model.predict(training_data)\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd4798c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred=np.argmax(x_pred,axis=1)\n",
    "x_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b36ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
